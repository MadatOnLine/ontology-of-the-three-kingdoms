{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP PROJECT - ONTOLOGY OF THE THREE KINGDOMS\n",
    "## Create & Fill Ontology via code!\n",
    "Spoiler: it was a failure T-T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries for using NLP techniques\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "#Importing library for working with excel files (easily importable to Protege witch Cellfie)\n",
    "#from openpyxl import Workbook\n",
    "\n",
    "#Importing library for dealing with ontology (OWL)\n",
    "from owlready2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gathering data from text\n",
    "file = open(\"Lists/Main Characters.txt\", \"r\");\n",
    "charText = file.readlines();\n",
    "file = open(\"Lists/Main Events.txt\", \"r\");\n",
    "eventText = file.readlines();\n",
    "file = open(\"Dataset/chap001-004.txt\", \"r\"); #change chapters to load\n",
    "#chap1Text = file.readlines();\n",
    "chaps = file.read();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjusting Stop Words\n",
    "lib_stopWords = set(stopwords.words('english'));\n",
    "stop_words = lib_stopWords.copy();\n",
    "\n",
    "for word in lib_stopWords:\n",
    "    #word[0] = word[0].upper(); #can't just change [0] value to [0].upper T-T\n",
    "    upWord = word[0].upper() + word[1:];\n",
    "    stop_words.add(upWord);\n",
    "\n",
    "for sign in punctuation:\n",
    "    stop_words.add(sign);\n",
    "    \n",
    "stop_words.add(\"”\");\n",
    "stop_words.add(\"“\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting local path to wanted ontology & load it \n",
    "onto_path.append(\"C:\\\\Put\\Your\\Path\\Here\"); # Put your own, MUST be FULL!\n",
    "onto = get_ontology(\"C:\\\\Put\\Your\\Path\\Here\\ontology-of-the-3-kingdoms.owl\").load();\n",
    "#If list != empty, ok!\n",
    "list(onto.classes())\n",
    "\n",
    "#list(onto.search(iri=\"*title\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OBJECTIVE - Creating instances via Python in order to populate ontology\n",
    "with onto:\n",
    "    class Years(Thing):\n",
    "        namespace = onto\n",
    "        pass\n",
    "list(onto.search(iri=\"*Years\"))\n",
    "print(onto_path[0] + \".OWLClass-Years\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(onto.individuals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Problem ~ The Reason Behind the Stop\n",
    "As far as I understand, in order to create and manipulate any kind of owl-object you first need to define it as a python class: I should (re)define in coherent way all classes, object-property and data-property that I created in Protégé. After that, create an individual is just like create an instance of a class in Python.<br>\n",
    "Aside from the fact that I'm having problem retrieving data from the loaded-ontology, I don't want to deal with the same thing, which I'm still learning on, in two different ways, forcing me to repeat whatever change I decide to make twice.<br>\n",
    "The risk of slowing me down is high so I'll stop this experiment for now."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
